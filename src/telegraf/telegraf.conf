# Telegraf Configuration
#
# Telegraf is entirely plugin driven. All metrics are gathered from the
# declared inputs, and sent to the declared outputs.
#
# Plugins must be declared in here to be active.
# To deactivate a plugin, comment out the name and any variables.
#
# Use 'telegraf -config telegraf.conf -test' to see what metrics a config
# file would generate.
#
# Environment variables can be used anywhere in this config file, simply prepend
# them with $. For strings the variable must be within quotes (ie, "$STR_VAR"),
# for numbers and booleans they should be plain (ie, $INT_VAR, $BOOL_VAR)


# Global tags can be specified here in key="value" format.
[global_tags]
  # dc = "us-east-1" # will tag all metrics with dc=us-east-1
  # rack = "1a"
  ## Environment variables can be used as tags, and throughout the config file
  # user = "$USER"


# Configuration for telegraf agent
[agent]
  ## Default data collection interval for all inputs
  interval = "10s"
  ## Rounds collection interval to 'interval'
  ## ie, if interval="10s" then always collect on :00, :10, :20, etc.
  round_interval = true

  ## Telegraf will send metrics to outputs in batches of at most
  ## metric_batch_size metrics.
  ## This controls the size of writes that Telegraf sends to output plugins.
  metric_batch_size = 1000

  ## For failed writes, telegraf will cache metric_buffer_limit metrics for each
  ## output, and will flush this buffer on a successful write. Oldest metrics
  ## are dropped first when this buffer fills.
  ## This buffer only fills when writes fail to output plugin(s).
  metric_buffer_limit = 10000

  ## Collection jitter is used to jitter the collection by a random amount.
  ## Each plugin will sleep for a random time within jitter before collecting.
  ## This can be used to avoid many plugins querying things like sysfs at the
  ## same time, which can have a measurable effect on the system.
  collection_jitter = "0s"

  ## Default flushing interval for all outputs. Maximum flush_interval will be
  ## flush_interval + flush_jitter
  flush_interval = "10s"
  ## Jitter the flush interval by a random amount. This is primarily to avoid
  ## large write spikes for users running a large number of telegraf instances.
  ## ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s
  flush_jitter = "0s"

  ## By default or when set to "0s", precision will be set to the same
  ## timestamp order as the collection interval, with the maximum being 1s.
  ##   ie, when interval = "10s", precision will be "1s"
  ##       when interval = "250ms", precision will be "1ms"
  ## Precision will NOT be used for service inputs. It is up to each individual
  ## service input to set the timestamp at the appropriate precision.
  ## Valid time units are "ns", "us" (or "Âµs"), "ms", "s".
  precision = ""

  ## Logging configuration:
  ## Run telegraf with debug log messages.
  debug = false
  ## Run telegraf in quiet mode (error log messages only).
  quiet = false
  ## Specify the log file name. The empty string means to log to stderr.
  logfile = ""

  ## Override default hostname, if empty use os.Hostname()
  hostname = ""
  ## If set to true, do no set the "host" tag in the telegraf agent.
  omit_hostname = false


###############################################################################
#                            OUTPUT PLUGINS                                   #
###############################################################################

# Configuration for sending metrics to InfluxDB
[[outputs.influxdb]]
  # The full HTTP or UDP URL for your InfluxDB instance.
  #
  # Multiple URLs can be specified for a single cluster, only ONE of the
  # urls will be written to each interval.
  urls = ["http://influxdb:8086"]

  # The target database for metrics; will be created as needed.
  database = "Metrics"

  # If true, no CREATE DATABASE queries will be sent.  Set to true when using
  # Telegraf with a user without permissions to create databases or when the
  # database already exists.
  skip_database_creation = true

  # Name of existing retention policy to write to.  Empty string writes to
  # the default retention policy.  Only takes effect when using HTTP.
  retention_policy = ""

  # Write consistency (clusters only), can be: "any", "one", "quorum", "all".
  # Only takes effect when using HTTP.
  write_consistency = "any"

  # Timeout for HTTP messages.
  timeout = "5s"

  # # HTTP Basic Auth
  username = "influx"
  password = "influx"

  # # HTTP User-Agent
  # user_agent = "telegraf"

  # # UDP payload size is the maximum packet size to send.
  # udp_payload = "512B"

  # # Optional TLS Config for use on HTTP connections.
  # tls_ca = "/etc/telegraf/ca.pem"
  # tls_cert = "/etc/telegraf/cert.pem"
  # tls_key = "/etc/telegraf/key.pem"
  # # Use TLS but skip chain & host verification
  # insecure_skip_verify = false

  # # HTTP Proxy override, if unset values the standard proxy environment
  # # variables are consulted to determine which proxy, if any, should be used.
  # http_proxy = "http://corporate.proxy:3128"

  # # Additional HTTP headers
  # http_headers = {"X-Special-Header" = "Special-Value"}

  # # HTTP Content-Encoding for write request body, can be set to "gzip" to
  # # compress body or "identity" to apply no encoding.
  # content_encoding = "identity"

  # # When true, Telegraf will output unsigned integers as unsigned values,
  # # i.e.: "42u".  You will need a version of InfluxDB supporting unsigned
  # # integer values.  Enabling this option will result in field type errors if
  # # existing data has been written.
  # influx_uint_support = false

# Collect statistics about itself
[[inputs.internal]]
  ## If true, collect telegraf memory stats.
  collect_memstats = true
  name_prefix = "telegraf."

[[inputs.docker]]
  endpoint = "unix:///var/run/docker.sock"
  name_prefix = "docker."

# # Read metrics from one or many prometheus clients
[[inputs.prometheus]]
  urls = ["http://influxdb:8000"]
  name_prefix = "influxdb."

[[inputs.prometheus]]
  ## An array of urls to scrape metrics from.
  urls = ["http://fake-logger:8000"]
  name_prefix = "fake-logger."

  ## An array of Kubernetes services to scrape metrics from.
  # kubernetes_services = ["http://my-service-dns.my-namespace:9100/metrics"]

  ## Kubernetes config file to create client from.
  # kube_config = "/path/to/kubernetes.config"

  ## Scrape Kubernetes pods for the following prometheus annotations:
  ## - prometheus.io/scrape: Enable scraping for this pod
  ## - prometheus.io/scheme: If the metrics endpoint is secured then you will need to
  ##     set this to 'https' & most likely set the tls config.
  ## - prometheus.io/path: If the metrics path is not /metrics, define it with this annotation.
  ## - prometheus.io/port: If port is not 9102 use this annotation
  # monitor_kubernetes_pods = true

  ## Use bearer token for authorization
  # bearer_token = /path/to/bearer/token

  ## Specify timeout duration for slower prometheus clients (default is 3s)
  # response_timeout = "3s"

  ## Optional TLS Config
  # tls_ca = /path/to/cafile
  # tls_cert = /path/to/certfile
  # tls_key = /path/to/keyfile
  ## Use TLS but skip chain & host verification
  # insecure_skip_verify = false
